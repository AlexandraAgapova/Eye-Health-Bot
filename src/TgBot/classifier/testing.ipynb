{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cad23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "path_to_h_u_model = \"../models/YOLO/healthy_unhealthy/classify/train/weights/best.pt\"\n",
    "path_to_b_dc_model = \"../models/YOLO/bags_circles/runs/classify/train2/weights/best.pt\"\n",
    "health_un_model = YOLO(path_to_h_u_model)\n",
    "bags_dc_model = YOLO(path_to_b_dc_model)\n",
    "\n",
    "models_ = [health_un_model, bags_dc_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d208b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=/home/m.sukhanov1/.venv/lib/python3.10/site-packages/ultralytics/assets'.\n",
      "\n",
      "image 1/2 /home/m.sukhanov1/.venv/lib/python3.10/site-packages/ultralytics/assets/bus.jpg: 224x224 healthy 0.97, unhealthy 0.03, 3.0ms\n",
      "image 2/2 /home/m.sukhanov1/.venv/lib/python3.10/site-packages/ultralytics/assets/zidane.jpg: 224x224 healthy 0.99, unhealthy 0.01, 3.0ms\n",
      "Speed: 7.6ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "results = health_un_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d4de5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747470635.919474 4137098 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747470635.937330 4137099 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "FACE_LANDMARKS = [10, 109, 67, 103, 54, 21, 162, 127, 227, 137, 177, 215, 138, 135, 136, 169, \n",
    "                  150, 149, 176, 148, 152, 377, 400, 378, 379, 365, 364, 397, 435, 401, \n",
    "                  366, 447, 366, 389, 251, 284, 332, 297, 338]\n",
    "\n",
    "# Инициализация MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "def process_image(image_path) -> tuple:\n",
    "    \"\"\"\n",
    "    Обрабатывает одно изображение, подготавливая его к inference и сохраняет результат\n",
    "    If image not found -> (None, 0)\n",
    "    If face not found -> (stock_image, 0)\n",
    "    If founded -> (cropped_image, 1)\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return (None, 0)\n",
    "    \n",
    "    # Конвертируем в RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Обработка лица\n",
    "    results = face_mesh.process(image_rgb)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        h, w = image.shape[:2]\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            points = []\n",
    "            for idx in FACE_LANDMARKS:\n",
    "                if idx < len(face_landmarks.landmark):\n",
    "                    lm = face_landmarks.landmark[idx]\n",
    "                    x, y = int(lm.x * w), int(lm.y * h)\n",
    "                    points.append((x, y))\n",
    "            \n",
    "            if len(points) > 2:\n",
    "                points_array = np.array(points, dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points_array], 255)\n",
    "                \n",
    "                # Находим ограничивающий прямоугольник\n",
    "                x, y, w_rect, h_rect = cv2.boundingRect(points_array)\n",
    "                \n",
    "                # Вырезаем область лица с небольшим запасом\n",
    "                padding = 10\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(w, x + w_rect + padding)\n",
    "                y2 = min(h, y + h_rect + padding)\n",
    "                \n",
    "                cropped = image[y1:y2, x1:x2]\n",
    "                \n",
    "                # Возвращаем полученное изображение\n",
    "                return (cropped, 1)\n",
    "    \n",
    "    return (image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80c5e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 unhealthy 1.00, healthy 0.00, 5.0ms\n",
      "Speed: 4.9ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 224x224 darkCircles 0.78, bags 0.22, 4.2ms\n",
      "Speed: 4.6ms preprocess, 4.2ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = \"/home/m.sukhanov1/ML/Eye_bags_detection/ML-Project/src/classifier/a294bba19001ec335a702476a3430594.jpg\"\n",
    "ready_to_classify_tuple = process_image(image)\n",
    "\n",
    "# отсекаем все изображения без лица\n",
    "if (ready_to_classify_tuple[1] == 0):\n",
    "    print(-1)\n",
    "\n",
    "results_hu = models_[0].predict(ready_to_classify_tuple[0])\n",
    "\n",
    "healthy_conf = results_hu[0].probs.data[0].item()\n",
    "unhealthy_conf = results_hu[0].probs.data[1].item()\n",
    "\n",
    "if (healthy_conf > 0.7):\n",
    "    print(0)\n",
    "else:\n",
    "    results_bc = models_[1].predict(ready_to_classify_tuple[0])\n",
    "    dark_circles_conf = results_bc[0].probs.data[0].item()\n",
    "    bags_conf = results_bc[0].probs.data[1].item()\n",
    "    if (dark_circles_conf > 0.4 and bags_conf > 0.4):\n",
    "        print(3)\n",
    "    if (dark_circles_conf > 0.4):\n",
    "        print(2)\n",
    "    else:\n",
    "        print(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ab781cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, models_):\n",
    "        self.models = models_\n",
    "\n",
    "    def predict(self, image : str)->int:\n",
    "        \"\"\"\n",
    "        not found face -> -1    \n",
    "        healthy -> 0    \n",
    "        bags -> 1   \n",
    "        dark_circles -> 2   \n",
    "        bags and dark_circles -> 3\n",
    "        \"\"\"\n",
    "        ready_to_classify_tuple = process_image(image)\n",
    "\n",
    "        # отсекаем все изображения без лица\n",
    "        if (ready_to_classify_tuple[1] == 0):\n",
    "            return -1\n",
    "\n",
    "        results_hu = models_[0].predict(ready_to_classify_tuple[0])\n",
    "\n",
    "        healthy_conf = results_hu[0].probs.data[0].item()\n",
    "\n",
    "        if (healthy_conf > 0.7):\n",
    "            return 0\n",
    "        else:\n",
    "            results_bc = models_[1].predict(ready_to_classify_tuple[0])\n",
    "            dark_circles_conf = results_bc[0].probs.data[0].item()\n",
    "            bags_conf = results_bc[0].probs.data[1].item()\n",
    "            if (dark_circles_conf > 0.4 and bags_conf > 0.4):\n",
    "                return 3\n",
    "            if (dark_circles_conf > 0.5):\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 unhealthy 1.00, healthy 0.00, 3.1ms\n",
      "Speed: 5.9ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 darkCircles 0.78, bags 0.22, 2.9ms\n",
      "Speed: 3.6ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "path_to_h_u_model = \"healthy_unhealthy.pt\"\n",
    "path_to_b_dc_model = \"bags_circles.pt\"\n",
    "health_un_model = YOLO(path_to_h_u_model)\n",
    "bags_dc_model = YOLO(path_to_b_dc_model)\n",
    "\n",
    "models_ = [health_un_model, bags_dc_model]\n",
    "\n",
    "orchestre = Classifier(models_) \n",
    "\n",
    "result = orchestre.predict(\"/home/m.sukhanov1/ML/Eye_bags_detection/ML-Project/src/classifier/a294bba19001ec335a702476a3430594.jpg\")\n",
    "\n",
    "if (result == -1):\n",
    "    print(\"Лицо не распознано\")\n",
    "if (result == 0):\n",
    "    print(\"лицо выглядит здоровым\")\n",
    "if (result == 1):\n",
    "    print(\"похоже, что у вас мешки под глазами\")\n",
    "if (result == 2):\n",
    "    print(\"Кажется, у вас черные круги\")\n",
    "if (result == 3):\n",
    "    print(\"дела плохи. и черные круги и мешки\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab30b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
